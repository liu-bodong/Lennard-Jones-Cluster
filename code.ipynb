{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a961ca72-a2e2-490c-8640-ff90ed69e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import generator\n",
    "import plotly.graph_objects as go\n",
    "from itertools import combinations\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059e854a-7289-44f4-bd0c-4663afb581e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def V(X, i, j):\n",
    "    r_ij = X[i] - X[j]\n",
    "    r = torch.norm(r_ij).pow(-6)\n",
    "    return r.pow(2) - 2 * r\n",
    "\n",
    "def center(X):\n",
    "    Y = X - X[0]\n",
    "    return Y\n",
    "    \n",
    "def system_potential(X):\n",
    "    N, _ = X.shape\n",
    "    energy = 0.0\n",
    "    Y = center(X)\n",
    "    for i in range(N - 1):\n",
    "        for j in range(i + 1, N): \n",
    "            energy += V(Y, i, j)\n",
    "    return energy\n",
    "\n",
    "def line_search(X, energy, g, alpha_0=1.0, factor=0.5, c=1e-4, max_iter=10, tol=1e-8):\n",
    "    alpha = alpha_0\n",
    "    dot = torch.sum(-g * g).item()    \n",
    "    for _ in range(max_iter):\n",
    "        X_k = X - alpha * g\n",
    "        energy_new = system_potential(X_k)\n",
    "\n",
    "        if energy_new <= energy + c * alpha * dot:\n",
    "            break\n",
    "        alpha *= factor\n",
    "        if alpha < tol:\n",
    "            break\n",
    "    return alpha\n",
    "\n",
    "def gd_solve(natoms, lr=0.008, energy_tol=1e-8, tol=1e-8, max_iter=2001, debug=True, debug_rate=400, save_initial=False, gen=generator.uniform_sphere, track_energy=False):\n",
    "    X = gen(natoms).clone().requires_grad_().to('cuda' if torch.cuda.is_available() else 'cpu', torch.float64)\n",
    "    if save_initial:\n",
    "        orig = X.clone()\n",
    "    if track_energy:\n",
    "        nrg_list = []\n",
    "\n",
    "    for _iter_ in range(max_iter):\n",
    "        energy = system_potential(X)\n",
    "        if track_energy:\n",
    "            nrg_list.append(energy.detach())\n",
    "        g = torch.autograd.grad(energy, X)[0] \n",
    "        \n",
    "        g_norm = g.norm().item()\n",
    "        if g_norm < tol:\n",
    "            if debug:\n",
    "                print(f\"Converged on step {_iter_}, energy: {energy.item():.6f}, gradient norm = {g_norm:.3e}\")\n",
    "            break\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            X -= line_search(X, energy, g) * g \n",
    "            X.requires_grad_() \n",
    "\n",
    "        energy_new = system_potential(X)\n",
    "\n",
    "        if abs(energy_new - energy) < energy_tol:\n",
    "            if debug:\n",
    "                print(f\"Converged on step {_iter_}, energy: {energy_new.item():.6f}, gradient norm = {g_norm:.3e}\")\n",
    "            break\n",
    "\n",
    "        if debug and _iter_ % debug_rate == 0:\n",
    "            print(f\"Step {_iter_}, energy: {energy.item():.6f}, gradient norm: {g_norm:.2e}\")\n",
    "    if save_initial:\n",
    "        return orig.detach(), center(X.detach()), energy    \n",
    "    if track_energy: \n",
    "        return torch.tensor(nrg_list), energy\n",
    "    return center(X.detach()), energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a60c0-23c4-4a87-9f39-d66bd82b947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d_points(points, energy):\n",
    "    points_np = center(points).numpy()\n",
    "    N,_ = points_np.shape\n",
    "    x = points_np[:, 0]\n",
    "    y = points_np[:, 1]\n",
    "    z = points_np[:, 2]\n",
    "    fig = go.Figure()\n",
    "    for i, j in combinations(range(len(points_np)), 2):\n",
    "        edge_len = np.linalg.norm(points_np[i] - points_np[j])\n",
    "        V_ij = V(points, i, j)\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[points_np[i, 0], points_np[j, 0]],\n",
    "            y=[points_np[i, 1], points_np[j, 1]],\n",
    "            z=[points_np[i, 2], points_np[j, 2]],\n",
    "            mode='lines',\n",
    "            line=dict(color='rgb(173, 216, 230, 0.4)', width=8),\n",
    "            showlegend=False, \n",
    "            hovertext=f\"Length: {edge_len:.2e}, Contributes {V_ij:.2e}J\",\n",
    "            hoverinfo=\"text\",\n",
    "        ))\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=x, y=y, z=z,\n",
    "        mode='markers',\n",
    "        hovertext=[f\"Point {i + 1}\" for i in range(N)],\n",
    "        marker=dict(size=8, color='red'),\n",
    "        showlegend=False\n",
    "    ))\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False, title=''),  # Remove grid, zero line, and ticks\n",
    "            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False, title=''),\n",
    "            zaxis=dict(showgrid=False, zeroline=False, showticklabels=False, title=''),\n",
    "        ),\n",
    "        title=f\"{N}-Atom Configuration: {energy:.4f}J\",\n",
    "        width=600,\n",
    "        height=400,\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "    )\n",
    "    fig.update_scenes(xaxis_visible=False, yaxis_visible=False,zaxis_visible=False)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73675db7-3339-41c2-8577-8d0dbbe92031",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for atoms in range(2,15):\n",
    "    config = gd_solve(atoms, debug=False)\n",
    "    plot_3d_points(*config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af3c7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that line search works right\n",
    "\n",
    "X = generator.uniform_sphere(3).clone().requires_grad_(True)\n",
    "for i in range(20):\n",
    "    E = system_potential(X)\n",
    "    g = torch.autograd.grad(E, X)[0]\n",
    "    p = -g.view(-1)                        \n",
    "    a = line_search(X, E, g, alpha_0=0.1)   # try 0.1 or whatever lr\n",
    "    with torch.no_grad():\n",
    "        X = X + a * p.view_as(X)\n",
    "        X = X - X[0]\n",
    "    X.requires_grad_(True)\n",
    "    print(f\"Iter {i:2d}: E = {E.item():.6f}, ‖grad‖ = {g.norm().item():.2e}, a = {a:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464babdc-52a0-4566-9a48-62b8b50b3947",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def strong_wolfe_line_search(X, energy, g, p,\n",
    "                             alpha0=1.0, c1=1e-4, c2=0.9,\n",
    "                             max_iter=20):\n",
    "    def phi(a):\n",
    "        Xt = X + a * p\n",
    "        return system_potential(Xt).item()\n",
    "    def der_phi(a):\n",
    "        Xt = X + a * p\n",
    "        Xt = Xt.clone().detach().requires_grad_(True)\n",
    "        Et = system_potential(Xt)\n",
    "        grad_t = torch.autograd.grad(Et, Xt)[0]\n",
    "        return (grad_t.view(-1) @ p.view(-1)).item()\n",
    "\n",
    "    alpha_prev = 0.0\n",
    "    phi0       = energy\n",
    "    derphi0    = (g.view(-1) @ p.view(-1)).item()\n",
    "    alpha = alpha0\n",
    "    phi_prev = phi0\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        phi_a = phi(alpha)\n",
    "        if (phi_a > phi0 + c1 * alpha * derphi0) or (i > 0 and phi_a >= phi_prev):\n",
    "            # need to zoom between alpha_prev and alpha\n",
    "            return zoom(alpha_prev, alpha, phi, der_phi, phi0, derphi0, c1, c2)\n",
    "        derphi_a = der_phi(alpha)\n",
    "        if abs(derphi_a) <= -c2 * derphi0:\n",
    "            return alpha\n",
    "        if derphi_a >= 0:\n",
    "            # curvature condition violated: derivative has changed sign\n",
    "            return zoom(alpha, alpha_prev, phi, der_phi, phi0, derphi0, c1, c2)\n",
    "        alpha_prev, phi_prev = alpha, phi_a\n",
    "        alpha = alpha * 2.0  # increase alpha and keep searching\n",
    "\n",
    "    return alpha  # fallback\n",
    "\n",
    "def zoom(a_lo, a_hi, phi, der_phi, phi0, derphi0, c1, c2):\n",
    "    for j in range(20):\n",
    "        # interpolate midpoint\n",
    "        a_j = 0.5 * (a_lo + a_hi)\n",
    "        phi_aj = phi(a_j)\n",
    "        if (phi_aj > phi0 + c1 * a_j * derphi0) or (phi_aj >= phi(a_lo)):\n",
    "            a_hi = a_j\n",
    "        else:\n",
    "            derphi_aj = der_phi(a_j)\n",
    "            if abs(derphi_aj) <= -c2 * derphi0:\n",
    "                return a_j\n",
    "            if derphi_aj * (a_hi - a_lo) >= 0:\n",
    "                a_hi = a_lo\n",
    "            a_lo = a_j\n",
    "    return a_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3686c0-5963-4a8e-9491-b68311a7ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfgs_step(X, energy, g, H_inv, alpha=1.0, max_iter=10, tol=1e-8):\n",
    "    N, _ = X.shape\n",
    "\n",
    "    # flatten & slice out the free variables\n",
    "    g_full = g.view(-1)\n",
    "    g_free = g_full[3:]\n",
    "    # print(\"||g_full|| =\", g_full.norm().item())\n",
    "    # print(\"||g_free|| =\", g_free.norm().item())\n",
    "    # print(\"H_inv diag:\", torch.diag(H_inv)[:6])\n",
    "    # print(\"H_inv.shape =\", H_inv.shape)\n",
    "    # print(\"g_free.shape =\", g_free.shape)\n",
    "\n",
    "    # descent dir in the free subspace\n",
    "    s_free = - H_inv @ g_free\n",
    "\n",
    "    p = torch.zeros_like(g_full, device=g_full.device)\n",
    "    p[3:] = s_free\n",
    "    p = p.view_as(X)\n",
    "\n",
    "    # line search (still uses the full X and full g)\n",
    "    alpha = strong_wolfe_line_search(X, energy, g, p)\n",
    "\n",
    "    # take a step in the free variables\n",
    "    x_full = X.clone().detach().view(-1)\n",
    "    x_free = x_full[3:]\n",
    "\n",
    "    # print(\"||s_free|| =\", s_free.norm().item())\n",
    "    # print(\"alpha =\", alpha)\n",
    "    # print(\"x_free (first 5) =\", x_free[:5])\n",
    "    x_free_new = x_free + alpha * s_free\n",
    "    # print(\"x_free_new (first 5) =\", x_free_new[:5])\n",
    "    # print(\"s = x_free_new - x_free (first 5) =\", (x_free_new - x_free)[:5])\n",
    "\n",
    "    # reassemble X_new\n",
    "    x_full[3:] = x_free_new\n",
    "    X_new = x_full.view(N,3).requires_grad_(True)\n",
    "\n",
    "    # eval new energy & gradient\n",
    "    energy_new = system_potential(X_new)\n",
    "    g_new_full = torch.autograd.grad(energy_new, X_new)[0]\n",
    "    g_new = g_new_full.view(-1)\n",
    "    g_new_free = g_new[3:]\n",
    "\n",
    "    # BFGS inverse‐Hessian update on the free subspace\n",
    "    w = alpha * s_free\n",
    "    y = g_new_free - g_free\n",
    "    # print (f\"y={y}\")\n",
    "    # print (f\"s={s}\")\n",
    "    # print (f\"ys={y @ s}\")\n",
    "    ys = (y @ w).item()\n",
    "    # print(f\"||s|| = {w.norm().item():.2e}, ||y|| = {y.norm().item():.2e}, y^T s = {ys:.2e}\")\n",
    "\n",
    "\n",
    "    if ys <= 1e-24:\n",
    "        H_inv_new = H_inv.clone()\n",
    "        valid = True\n",
    "    else:\n",
    "        #print (\"does this run\")\n",
    "        rho = 1.0 / ys\n",
    "        I   = torch.eye(H_inv.shape[0], device=H_inv.device)\n",
    "        V   = I - rho * torch.outer(w, y)\n",
    "        with torch.no_grad():\n",
    "            H_inv_new = V @ H_inv @ V.T + rho * torch.outer(w, w)\n",
    "        valid = True\n",
    "\n",
    "    return X_new, energy_new, g_new_full, H_inv_new, alpha, valid\n",
    "\n",
    "def bfgs(natoms, lr=0.008, g_tol=1e-8, energy_tol=1e-8, max_iter=2001, debug=True, debug_rate=400, save_initial=False, gen=generator.uniform_sphere, track_energy=False):\n",
    "    X = gen(natoms).clone().requires_grad_().to('cuda' if torch.cuda.is_available() else 'cpu', torch.float64)\n",
    "    if save_initial:\n",
    "        orig = X.clone()\n",
    "    N, _ = X.shape\n",
    "    H_inv = torch.eye(3 * (N - 1), dtype=torch.float64).to(X.device) \n",
    "\n",
    "    X = X.clone().detach().requires_grad_(True) # make sure autograd returns valid\n",
    "\n",
    "    if track_energy: \n",
    "        nrg_list = [system_potential(X)]\n",
    "    for _iter_ in range(max_iter):\n",
    "        energy = system_potential(X)\n",
    "        g = torch.autograd.grad(energy, X)[0]\n",
    "\n",
    "        X_new, energy_new, g_new, H_inv, alpha, valid = bfgs_step(X, energy, g, H_inv, alpha=lr)\n",
    "\n",
    "        if track_energy and valid: \n",
    "            nrg_list.append(energy_new.detach())\n",
    "        \n",
    "        if abs(energy_new - energy) < energy_tol:\n",
    "            if debug:\n",
    "                print(f\"Converged on step {_iter_}, energy: {energy_new.item():.6f}, gradient norm = {g_norm:.3e}\")\n",
    "            break\n",
    "\n",
    "        g_norm = g.norm().item()\n",
    "        if g_norm < g_tol:\n",
    "            if debug:\n",
    "                print(f\"Converged on step {_iter_}, energy: {energy.item():.6f}, gradient norm = {g_norm:.3e}\")\n",
    "            break\n",
    "        \n",
    "        if debug and _iter_ % debug_rate == 0:\n",
    "            print(f\"Step {_iter_}, energy: {energy_new.item():.6f}, gradient norm: {g_norm:.2e}, step size: {alpha:.4e}\")\n",
    "        \n",
    "        X, energy = X_new, energy_new\n",
    "\n",
    "    if save_initial:\n",
    "        return orig.detach(), X.detach(), energy_new \n",
    "    if track_energy: \n",
    "        print (len(nrg_list))\n",
    "        return torch.tensor(nrg_list), energy_new\n",
    "\n",
    "    return X.detach(), energy_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7556e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = bfgs(15, debug=True, g_tol=1e-8, energy_tol=1e-12, debug_rate=20, track_energy=False)\n",
    "plot_3d_points(*config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bd98dd-7148-4699-acba-da11e4dde82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for atoms in range(2,10):\n",
    "    config = bfgs(atoms, debug=False, g_tol=1e-8, energy_tol=1e-8, debug_rate=20)\n",
    "    plot_3d_points(*config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55a135c-fb4b-480c-93e2-eb810bf220e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_convergence_order(energies, final_energy, label=\"\"):\n",
    "    \"\"\"\n",
    "    energies: 1D tensor [E0, E1, ..., E_N]\n",
    "    final_energy: scalar tensor E*\n",
    "    \n",
    "    Plots (log10 e_n, log10 e_{n+1}) with a linear fit whose slope ≈ order p.\n",
    "    \"\"\"\n",
    "    # 1) drop last energy\n",
    "    E = energies[:-1]\n",
    "    # 2) absolute errors\n",
    "    errs = (E - final_energy).abs()\n",
    "    # 3) log10 errors, set zeros to -inf\n",
    "    log_err = torch.where(errs > 0,\n",
    "                          errs.log10(),\n",
    "                          torch.full_like(errs, float(\"-inf\")))\n",
    "    # 4) keep only finite entries\n",
    "    mask = torch.isfinite(log_err)\n",
    "    log_err = log_err[mask]\n",
    "    # 5) x = log_err[:-1], y = log_err[1:]\n",
    "    x = log_err[:-1]\n",
    "    y = log_err[1:]\n",
    "    # 6) compute slope p and intercept a in torch\n",
    "    xm = x.mean()\n",
    "    ym = y.mean()\n",
    "    num = ((x - xm) * (y - ym)).sum()\n",
    "    den = ((x - xm)**2).sum()\n",
    "    p = num / den              # slope\n",
    "    a = ym - p * xm            # intercept\n",
    "    \n",
    "    # 7) convert to NumPy for plotting\n",
    "    x_np = x.detach().numpy()\n",
    "    y_np = y.detach().numpy()\n",
    "    p_val = p.item()\n",
    "    a_val = a.item()\n",
    "    \n",
    "    # 8) plot\n",
    "    plt.figure()\n",
    "    plt.plot(x_np, y_np, \"o\", label=\"data\")\n",
    "    plt.plot(x_np, p_val * x_np + a_val, \"-\", label=f\"slope ≈ {p_val:.2f}\")\n",
    "    plt.xlabel(\"log10(error_n)\")\n",
    "    plt.ylabel(\"log10(error_{n+1})\")\n",
    "    plt.title(f\"Estimated {label}Convergence Order p ≈ {p_val:.2f}\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_convergence(energies, final_energy, label=\"\"):\n",
    "    \"\"\"\n",
    "    Plots the convergence of absolute errors on a log10 scale,\n",
    "    ignoring the last entry in the energies tensor.\n",
    "    \n",
    "    energies: 1D torch.Tensor of computed energies [E0, E1, ..., EN]\n",
    "    final_energy: scalar torch.Tensor (or float castable) E*\n",
    "    \"\"\"\n",
    "    # drop the last computed energy\n",
    "    E = energies[:-1]\n",
    "    errors = (E - final_energy).abs()\n",
    "    \n",
    "    # compute log10(errors), putting -inf where error is zero\n",
    "    log_errors = torch.where(\n",
    "        errors > 0,\n",
    "        errors.log10(),\n",
    "        torch.full_like(errors, float(\"-inf\"))\n",
    "    )\n",
    "    \n",
    "    # move to CPU+NumPy for plotting\n",
    "    iters = torch.arange(log_errors.size(0)).cpu().numpy()\n",
    "    log_e = log_errors.detach().numpy()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(iters, log_e, marker='o')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('log10(|Error|)')\n",
    "    plt.title(f'{label}Convergence on Log Scale')\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "    plot_convergence_order(energies, final_energy, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6054cc-7ccb-4a42-bdf9-744c490fc2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence(*(gd_solve(15, track_energy=True, debug=False, gen=generator.init_pos)), label=\"GD \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef0d6bd-f9c4-499c-8939-2b8737d8109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence(*(bfgs(8, track_energy=True, debug=False, gen=generator.uniform_sphere)), label=\"BFGS \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258f023b-b737-48ef-a0f9-d60fe472b4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlc-config",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
